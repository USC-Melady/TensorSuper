{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADMM solver for tensor completion with n-rank minimization\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from math_utils import *\n",
    "from scipy import linalg\n",
    "from sktensor import ktensor\n",
    "\n",
    "def gen_orth_tensor(input_shape,R):\n",
    "    # all orthogonal cases\n",
    "    U = np.random.random((input_shape[0], R))\n",
    "    U_orth = linalg.orth(U)\n",
    "\n",
    "    V = np.random.random((input_shape[1], R))\n",
    "    V_orth = linalg.orth(V)\n",
    "\n",
    "    W = np.random.random((input_shape[2], R))\n",
    "    W_orth = linalg.orth(W)\n",
    "\n",
    "    Lambda = np.random.random((R,))\n",
    "\n",
    "    X = ktensor([U_orth, V_orth, W_orth], lmbda=Lambda)\n",
    "    X_ten = np.asarray(X.totensor())\n",
    "\n",
    "    return X_ten\n",
    "\n",
    "\n",
    "def exact_update(Omega,X, Ws, Ys, params):\n",
    "    \"\"\"Exact update of the primal variable\"\"\"\n",
    "    num_modes = np.ndim(Omega)\n",
    "    beta_val = params['beta']\n",
    "    lambda_val  = params['lambda']\n",
    "    \n",
    "    W_Y_sum = np.sum(W_m + beta_val * Y_m for W_m in Ws for Y_m in Ys)\n",
    "    X_out = 1.0/(lambda_val +  num_modes * beta_val) * (W_Y_sum + lambda_val * X)   \n",
    "    X_out[Omega==0] = 1.0/(num_modes * beta_val)*W_Y_sum[Omega==0]\n",
    "    \n",
    "    return X_out\n",
    "\n",
    "\n",
    "def inexact_update(Omega, X, Ws, Ys):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "def tc_loss(X_out, Omega, X, Ws,Ys, params):\n",
    "    \"\"\"loss function of tensor completion\"\"\"\n",
    "    num_modes = np.ndim(X)\n",
    "    loss = 0.0;\n",
    "    loss += params['lambda']*0.5 * np.square(tensor_norm(np.subtract(X_out[Omega==1],X[Omega==1]), 'fro'))\n",
    "    for mode in range(num_modes):\n",
    "        loss += np.linalg.norm(unfold(Ys[mode], mode),'nuc')\n",
    "        loss += np.sum(np.multiply(Ws[mode], Ys[mode] - X_out))\n",
    "        loss += params['beta'] *0.5* np.square(tensor_norm(np.subtract(Ys[mode],X_out),'fro'))\n",
    "    return loss\n",
    "                                             \n",
    "                                             \n",
    "def tensor_complete_ADMM(Omega, X, succ_thres,params):\n",
    "    num_modes = np.ndim(X)\n",
    "    beta_val =  params['beta']\n",
    "    lambda_val = params['lambda']\n",
    "    X_out = np.zeros(X.shape)\n",
    "    Ws = [np.zeros(X.shape)] * num_modes\n",
    "    Ys = [np.zeros(X.shape)] * num_modes\n",
    "    loss = np.zeros((max_iter+1,1))\n",
    "    loss_val = tc_loss(X_out, Omega, X, Ws,Ys, params)\n",
    "    loss[0] = loss_val\n",
    "    if params['verbose']:\n",
    "        print'start:{}'.format(loss_val)\n",
    "    for k in range(params['max_iter']):\n",
    "#         params['lambda'] = params['lambda']*c_lambda\n",
    "#         params['beta'] = params['beta'] * c_beta\n",
    "        X_out_new  = exact_update(Omega, X, Ws, Ys, params)\n",
    "        loss_val_new = tc_loss(X_out_new, Omega, X, Ws,Ys, params)\n",
    "        loss[k+1] = loss_val_new\n",
    "        if params['verbose']:\n",
    "            print'iter {}:{}'.format(k, loss_val_new)\n",
    "        if  abs((loss_val_new-loss_val)/loss_val) < params['stop_thres']:\n",
    "            loss[k+1:] = loss_val_new\n",
    "            break;\n",
    "        X_out = np.copy(X_out_new)\n",
    "        loss_val = np.copy(loss_val_new)\n",
    "\n",
    "        for mode in range(num_modes):\n",
    "            X_W_mat = unfold(X_out,mode) - 1.0/beta_val * unfold(Ws[mode],mode)\n",
    "            Y_m = shrink(X_W_mat, 1.0/beta_val)\n",
    "            Ys[mode] = fold(Y_m, mode, X.shape)\n",
    "            Ws[mode] = Ws[mode] - beta_val * (X_out[mode]- Ys[mode])\n",
    "       \n",
    "    return (X_out,loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sktensor import dtensor, cp_als\n",
    "\n",
    "def hard_thres():\n",
    "    \n",
    "def RTPM(X):\n",
    "    \"\"\"robust tensor power method\"\"\"\n",
    "    X_out = np.zeros(X.shape)\n",
    "    pass\n",
    "\n",
    "def TPM(X):\n",
    "    T = dtensor(X)\n",
    "    P, fit, itr, exectimes = cp_als(T, 3, init='random')\n",
    "    return (P.Lambda, P.U)\n",
    "\n",
    "    \n",
    "def tensor_complete_ALS(Omega, X, succ_thres,params ):\n",
    "    \"\"\"implementation of [Jain 2014]\"\"\"\n",
    "    [Lambda,U0] = RTPM(X) # tensor power method initialization\n",
    "    [U] = hard_thres(U0)\n",
    "    for k in range(max_iter):\n",
    "        for r in range(R):\n",
    "            u1= rank_one_ls(Omega, X, U)\n",
    "            Lambda(r) = norm(u1)\n",
    "            U[:,r] = u1/ Lambda(r)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:52: RuntimeWarning: overflow encountered in multiply\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:49: RuntimeWarning: overflow encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:1825: RuntimeWarning: overflow encountered in add\n",
      "  res = _sum_(a)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test routine  for TensorComplete\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "var_shape = (5,6,8)\n",
    "rank_val = 2\n",
    "Omega = np.random.rand(*var_shape)\n",
    "Omega = np.array(Omega < 0.8)\n",
    "X = gen_orth_tensor(var_shape, rank_val)\n",
    "\n",
    "X_obv = np.copy(X)\n",
    "X_obv[Omega ==0] = 0\n",
    "succ_thres = np.float32(1e-3)\n",
    "beta_val = np.float32(1)\n",
    "lambda_val = np.float32(1e2)\n",
    "c_beta = np.float32(1)\n",
    "c_lambda = np.float32(1e-3)\n",
    "VERBOSE = False\n",
    "max_iter = np.int32(1e4);\n",
    "stop_thres = np.float32(1e-6);\n",
    "params = {'beta':beta_val, 'lambda':lambda_val,'verbose':VERBOSE,\n",
    "          'max_iter':max_iter, 'stop_thres':stop_thres}\n",
    "X_out, loss= tensor_complete_ADMM(Omega, X_obv, succ_thres, params)\n",
    "print 'error ratio:', tensor_norm(np.subtract(X_out,X),'fro')/tensor_norm(X, 'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print X\n",
    "# print X_obv\n",
    "# print X_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
